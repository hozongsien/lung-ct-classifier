{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import shutil\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D, LeakyReLU, AveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.optimizers import Ftrl\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.nn import leaky_relu\n",
    "from tensorflow.keras.applications import Xception, VGG19, InceptionV3, ResNet50V2, InceptionResNetV2\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.layers.experimental import RandomFourierFeatures\n",
    "from tensorflow.keras.losses import Hinge\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clahe(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=4, tileGridSize=(40, 40))\n",
    "    img = clahe.apply(img)\n",
    "    img = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.listdir(\"nus-cs5242/train_image/train_image\")\n",
    "out_path = \"nus-cs5242/preprocessed/\"\n",
    "for index in range(len(train_path)):\n",
    "    img_path = \"nus-cs5242/train_image/train_image/\" + train_path[index]\n",
    "    img = apply_clahe(img_path)\n",
    "    cv2.imwrite(out_path + train_path[index], img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nus-cs5242/preprocessed/0.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'nus-cs5242/preprocessed/0.png' -> 'nus-cs5242/preprocessed/1/0.png'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-32a1aa2c93fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mimage_src_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimage_dst_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_src_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_dst_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m             \u001b[0mcopy_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    803\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m     \u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m             \u001b[1;31m# macOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nus-cs5242/preprocessed/0.png'"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv('nus-cs5242/train_label.csv')\n",
    "image_path = \"nus-cs5242/preprocessed/\"\n",
    "for index, value in labels.iterrows():\n",
    "    image_src_path = image_path + str(value.ID) + \".png\"\n",
    "    image_dst_path = image_path + str(value.Label) + \"/\" + str(value.ID) + \".png\"\n",
    "    shutil.move(image_src_path, image_dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 933 images belonging to 3 classes.\n",
      "Found 231 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "my_seed = 5242\n",
    "img_directory = \"nus-cs5242/preprocessed\"\n",
    "datagen = ImageDataGenerator(brightness_range=(0.3, 1.0), rescale=1./255, validation_split=0.2)\n",
    "train_datagen = datagen.flow_from_directory(img_directory, target_size=(512, 512), seed=my_seed, subset='training')\n",
    "validation_datagen = datagen.flow_from_directory(img_directory, target_size=(512, 512), seed=my_seed, subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(train_datagen.labels)\n",
    "weight_for_0 = (1 / sum(train_datagen.labels == 0))*(total)/3.0\n",
    "weight_for_1 = (1 / sum(train_datagen.labels == 1))*(total)/3.0\n",
    "weight_for_2 = (1 / sum(train_datagen.labels == 2))*(total)/3.0\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(weights='imagenet', input_shape=(512, 512, 3), include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "add_model = Sequential()\n",
    "add_model.add(base_model)\n",
    "add_model.add(Conv2D(128, (3, 3)))\n",
    "# add_model.add(LeakyReLU())\n",
    "add_model.add(Conv2D(128, (3, 3)))\n",
    "# add_model.add(LeakyReLU())\n",
    "add_model.add(Conv2D(128, (3, 3)))\n",
    "add_model.add(BatchNormalization())\n",
    "add_model.add(Activation('relu'))\n",
    "add_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# add_model.add(Dropout(0.3))\n",
    "add_model.add(Flatten())\n",
    "add_model.add(RandomFourierFeatures(output_dim=128, kernel_initializer=\"gaussian\"))\n",
    "# add_model.add(Dropout(0.3))\n",
    "add_model.add(Dense(3, activation = 'softmax', kernel_regularizer='l1_l2'))\n",
    "\n",
    "model = add_model\n",
    "model.compile(loss=Hinge(), optimizer=Adamax(), metrics=[CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 57s 2s/step - loss: 1.2490 - categorical_accuracy: 0.7631 - val_loss: 1.4395 - val_categorical_accuracy: 0.5195\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 22s 746ms/step - loss: 1.1226 - categorical_accuracy: 0.8853 - val_loss: 1.2417 - val_categorical_accuracy: 0.7835\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 22s 748ms/step - loss: 1.0454 - categorical_accuracy: 0.9496 - val_loss: 1.0622 - val_categorical_accuracy: 0.9177\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 22s 749ms/step - loss: 0.9895 - categorical_accuracy: 0.9689 - val_loss: 1.0106 - val_categorical_accuracy: 0.9177\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 22s 749ms/step - loss: 0.9489 - categorical_accuracy: 0.9775 - val_loss: 0.9740 - val_categorical_accuracy: 0.9307\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 23s 750ms/step - loss: 0.9130 - categorical_accuracy: 0.9839 - val_loss: 0.9469 - val_categorical_accuracy: 0.9437\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 23s 752ms/step - loss: 0.8821 - categorical_accuracy: 0.9893 - val_loss: 0.9228 - val_categorical_accuracy: 0.9351\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 23s 750ms/step - loss: 0.8577 - categorical_accuracy: 0.9936 - val_loss: 0.9120 - val_categorical_accuracy: 0.9177\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 23s 751ms/step - loss: 0.8388 - categorical_accuracy: 0.9968 - val_loss: 0.8896 - val_categorical_accuracy: 0.9524\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 23s 750ms/step - loss: 0.8227 - categorical_accuracy: 0.9979 - val_loss: 0.8762 - val_categorical_accuracy: 0.9567\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 23s 751ms/step - loss: 0.8102 - categorical_accuracy: 0.9979 - val_loss: 0.8665 - val_categorical_accuracy: 0.9654\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 23s 752ms/step - loss: 0.8014 - categorical_accuracy: 0.9989 - val_loss: 0.8557 - val_categorical_accuracy: 0.9610\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 23s 752ms/step - loss: 0.7937 - categorical_accuracy: 0.9989 - val_loss: 0.8472 - val_categorical_accuracy: 0.9697\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 23s 752ms/step - loss: 0.7885 - categorical_accuracy: 0.9989 - val_loss: 0.8441 - val_categorical_accuracy: 0.9524\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 23s 753ms/step - loss: 0.7837 - categorical_accuracy: 0.9989 - val_loss: 0.8368 - val_categorical_accuracy: 0.9610\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 23s 753ms/step - loss: 0.7801 - categorical_accuracy: 1.0000 - val_loss: 0.8338 - val_categorical_accuracy: 0.9567\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 23s 751ms/step - loss: 0.7770 - categorical_accuracy: 1.0000 - val_loss: 0.8307 - val_categorical_accuracy: 0.9567\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 23s 752ms/step - loss: 0.7743 - categorical_accuracy: 1.0000 - val_loss: 0.8312 - val_categorical_accuracy: 0.9524\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 23s 752ms/step - loss: 0.7729 - categorical_accuracy: 1.0000 - val_loss: 0.8220 - val_categorical_accuracy: 0.9697\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 23s 754ms/step - loss: 0.7709 - categorical_accuracy: 1.0000 - val_loss: 0.8250 - val_categorical_accuracy: 0.9610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cfec1333a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_datagen, validation_data=validation_datagen, epochs=20, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(775, len(base_model.layers)):\n",
    "    if ('batch_normalization' not in base_model.layers[i].name):\n",
    "        base_model.layers[i].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 23s 783ms/step - loss: 0.1139 - categorical_accuracy: 1.0000 - val_loss: 0.2343 - val_categorical_accuracy: 0.9567\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 23s 751ms/step - loss: 0.1132 - categorical_accuracy: 1.0000 - val_loss: 0.2289 - val_categorical_accuracy: 0.9610\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 23s 753ms/step - loss: 0.1128 - categorical_accuracy: 1.0000 - val_loss: 0.2301 - val_categorical_accuracy: 0.9610\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 23s 754ms/step - loss: 0.1126 - categorical_accuracy: 1.0000 - val_loss: 0.2303 - val_categorical_accuracy: 0.9610\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 23s 753ms/step - loss: 0.1125 - categorical_accuracy: 1.0000 - val_loss: 0.2339 - val_categorical_accuracy: 0.9524\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 23s 754ms/step - loss: 0.1122 - categorical_accuracy: 1.0000 - val_loss: 0.2208 - val_categorical_accuracy: 0.9654\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 23s 753ms/step - loss: 0.1123 - categorical_accuracy: 1.0000 - val_loss: 0.2160 - val_categorical_accuracy: 0.9610\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 23s 754ms/step - loss: 0.1120 - categorical_accuracy: 1.0000 - val_loss: 0.2268 - val_categorical_accuracy: 0.9610\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 23s 753ms/step - loss: 0.1118 - categorical_accuracy: 1.0000 - val_loss: 0.2220 - val_categorical_accuracy: 0.9610\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 23s 754ms/step - loss: 0.1116 - categorical_accuracy: 1.0000 - val_loss: 0.2301 - val_categorical_accuracy: 0.9610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cffc553640>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=Adamax(1e-5),  # Very low learning rate\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[CategoricalAccuracy()])\n",
    "model.fit(train_datagen, validation_data=validation_datagen, epochs=10, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yap Ying Ying\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Yap Ying Ying\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model_clahe2_rff\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model_clahe2_rff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
