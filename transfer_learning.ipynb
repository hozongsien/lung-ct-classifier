{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TqOt6Sv7AsMi"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow_addons as tfa\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v77rlkCKW0IJ"
   },
   "source": [
    "# data_preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds, model_params, batch_size, ds_type='train'):\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "    resize_and_rescale = create_resize_and_rescale_layer(model_params)\n",
    "    data_augmentation = create_augmentation_layer()\n",
    "\n",
    "    if ds_type == 'test':\n",
    "        ds = ds.map(lambda ds: (ds['image'], ds['label']))\n",
    "\n",
    "    ds = ds.map(lambda x, y: (resize_and_rescale(x), y), num_parallel_calls=AUTOTUNE) # disable to visualise train/ valid images\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    if ds_type == 'train':\n",
    "        ds = ds.map(lambda x, y: (data_augmentation(x), y), num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    if ds_type == 'train' or ds_type == 'valid': \n",
    "        ds = ds.map(lambda x, y: (x, tf.one_hot(y, depth=model_params['num_classes'])))\n",
    "    \n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def ensemble_input(ds, ds_type='train'):\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    if ds_type == 'train' or ds_type == 'valid':\n",
    "        ds = ds.map(lambda x, y: ({ 'ensemble_0_input_2': x, 'ensemble_1_input_2': x, 'ensemble_2_input_2': x}, y))\n",
    "    if ds_type == 'test':\n",
    "        ds = ds.map(lambda ds: ({ 'ensemble_0_input_2': ds['image'], 'ensemble_1_input_2': ds['image'], 'ensemble_2_input_2': ds['image']}, ds['label']))\n",
    "    \n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def create_resize_and_rescale_layer(model_params): \n",
    "    resize_and_rescale = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.Resizing(\n",
    "            model_params['image_shape'][0], \n",
    "            model_params['image_shape'][1], \n",
    "            interpolation='bilinear'\n",
    "        ),\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
    "    ], name='resize_and_rescale')\n",
    "    return resize_and_rescale\n",
    "\n",
    "\n",
    "def create_augmentation_layer():\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    ], name='data_augmentation')\n",
    "    return data_augmentation\n",
    "\n",
    "\n",
    "def make_generator(seed=None):\n",
    "    if seed:\n",
    "        return tf.random.Generator.from_seed(seed)\n",
    "    else:\n",
    "        return tf.random.Generator.from_non_deterministic_state()\n",
    "\n",
    "\n",
    "def random_invert_img(x, p=0.5):\n",
    "    if tf.random.uniform([]) < p:\n",
    "        x = (255-x)\n",
    "    else:\n",
    "        x\n",
    "    return x\n",
    "\n",
    "\n",
    "class RandomInvert(tf.keras.layers.Layer):\n",
    "    def __init__(self, factor=0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.factor = factor\n",
    "    \n",
    "    def call(self, x):\n",
    "        return random_invert_img(x)\n",
    "\n",
    "\n",
    "\n",
    "class RandomSheer(tf.keras.layers.Layer):\n",
    "    def __init__(self, seed=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.rng = make_generator(seed)\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        x_level = self.rng.uniform(shape=[], minval=0.1, maxval=0.35)\n",
    "        y_level = self.rng.uniform(shape=[], minval=0.1, maxval=0.35)\n",
    "\n",
    "        x = tfa.image.shear_x(x, x_level, 0)\n",
    "        x = tfa.image.shear_y(x, y_level, 0)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RandomGaussionFilter(tf.keras.layers.Layer):\n",
    "    def __init__(self, seed=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        k = np.random.randint(3, 11)\n",
    "        sigma = np.random.uniform(low=0.1, high=0.9)\n",
    "        x = tfa.image.gaussian_filter2d(x, filter_shape=(k, k), sigma=sigma)\n",
    "        return x\n"
   ]
  },
  {
   "source": [
    "# utils.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(acc, val_acc, loss, val_loss, initial_epochs=0):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()), 1.0])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    if initial_epochs != 0:\n",
    "        plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "            plt.ylim(), label='Start Fine Tuning')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0, 1.0])\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    if initial_epochs != 0:\n",
    "        plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "            plt.ylim(), label='Start Fine Tuning')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def save_results(image_ids, predicted_labels, save_path):\n",
    "    results = image_ids.drop('image', axis=1)\n",
    "    results.columns = ['ID', 'Label']\n",
    "    results['Label'] = predicted_labels \n",
    "    results = results.sort_values('ID').reset_index(drop=True)\n",
    "    results.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveConcatPooling(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(AdaptiveConcatPooling, self).__init__()\n",
    "\n",
    "    \n",
    "    def call(self, x):\n",
    "        output_size = (x.shape[1], x.shape[2])\n",
    "        avg_pool = tfa.layers.AdaptiveAveragePooling2D(output_size)(x)\n",
    "        max_pool = tfa.layers.AdaptiveMaxPooling2D(output_size)(x)\n",
    "        return tf.concat([avg_pool, max_pool], axis=1)\n",
    "\n",
    "\n",
    "def create_base_model(model_type, img_shape):\n",
    "    if model_type == 'mobile':\n",
    "        base_model = tf.keras.applications.MobileNetV2(\n",
    "            input_shape=img_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "    elif model_type == 'xception':\n",
    "        base_model = tf.keras.applications.Xception(\n",
    "            input_shape=img_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "        )\n",
    "    elif model_type == 'res':\n",
    "        base_model = tf.keras.applications.ResNet152V2(\n",
    "            input_shape=img_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "        )\n",
    "    else:\n",
    "        raise RuntimeError(f'model_type={model_type} unsupported')\n",
    "\n",
    "    base_model.trainable = False\n",
    "    return base_model\n",
    "\n",
    "\n",
    "def create_prediction_layer(head_type, num_classes, hyperparams):\n",
    "    if head_type == 'standard':\n",
    "        prediction = tf.keras.Sequential([\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dropout(hyperparams['dropout']),\n",
    "            tf.keras.layers.Dense(num_classes, name='logits'),\n",
    "            tf.keras.layers.Activation('softmax', dtype='float32', name='probs'), # separate activation layer for mixed precision support \n",
    "        ], name='prediction')\n",
    "    elif head_type == 'adaptive':\n",
    "        prediction = tf.keras.Sequential([\n",
    "            AdaptiveConcatPooling(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(0.75),\n",
    "            tf.keras.layers.Dense(num_classes, name='logits'),\n",
    "            tf.keras.layers.Activation('softmax', dtype='float32', name='probs'),\n",
    "        ], name='prediction')\n",
    "    else:\n",
    "        raise RuntimeError(f'head_type={head_type} unsupported')\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "\n",
    "def create_model(image_shape, num_classes, hyperparams, model_type='mobile', head_type='standard'):\n",
    "    base_model = create_base_model(model_type, image_shape)\n",
    "    prediction_layer = create_prediction_layer(head_type, num_classes, hyperparams)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=image_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    outputs = prediction_layer(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_fine_tune_model(model, hyperparams):\n",
    "    print(\"Number of layers in the base model: \", len(model.layers[1].layers))\n",
    "    model.layers[1].trainable = True\n",
    "    for layer in model.layers[1].layers[:hyperparams['fine_tune_at']]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_ensmble_models():\n",
    "    filenames = ['Xception09.1-1_fold', 'MobileNet03-1_fold', 'ResNet03-1_fold']\n",
    "    models = []\n",
    "    for i, name in enumerate(filenames):\n",
    "        model = tf.keras.models.load_model(os.path.join('models', name, '.h5'))\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "            layer._name = f'ensemble_{i}_{layer.name}'\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "def create_ensemble_prediction_layer():\n",
    "    prediction = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, name='logits'),\n",
    "        tf.keras.layers.Activation('softmax', dtype='float32', name='probs'),\n",
    "    ], name='prediction')\n",
    "    return prediction\n",
    "\n",
    "    \n",
    "def create_ensemble_model():\n",
    "    models = load_ensmble_models()\n",
    "    prediction_layer = create_ensemble_prediction_layer()\n",
    "    \n",
    "    ensemble_inputs = [model.input for model in models]\n",
    "    ensemble_outputs = [model.output for model in models]\n",
    "    concat = tf.keras.layers.concatenate(ensemble_outputs)\n",
    "    outputs = prediction_layer(concat)\n",
    "    model = tf.keras.Model(inputs=ensemble_inputs, outputs=outputs)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(model, train_ds, valid_ds, hyperparams, initial_epoch, num_epochs, callbacks):    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hyperparams['learning_rate']\n",
    "        ),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(\n",
    "            label_smoothing=0.1\n",
    "        ),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=valid_ds,\n",
    "        initial_epoch=initial_epoch,\n",
    "        epochs=num_epochs,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    return model, history\n",
    "\n",
    "\n",
    "def feature_extract_and_fine_tune(experiment_name, train_ds, valid_ds, model_params, base_hyperparams, fine_hyperparams):\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=os.path.join('logs', experiment_name)\n",
    "    )\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = create_model(model_params['image_shape'], model_params['num_classes'], base_hyperparams)\n",
    "    model, history = train_validate(\n",
    "        model=model, \n",
    "        train_ds=train_ds, \n",
    "        valid_ds=valid_ds, \n",
    "        hyperparams=base_hyperparams, \n",
    "        initial_epoch=0, \n",
    "        num_epochs=base_hyperparams['num_epochs'],\n",
    "        callbacks=[tensorboard_callback]\n",
    "    )\n",
    "\n",
    "    model = create_fine_tune_model(model, fine_hyperparams)\n",
    "    model, history = train_validate(\n",
    "        model=model, \n",
    "        train_ds=train_ds, \n",
    "        valid_ds=valid_ds, \n",
    "        hyperparams=fine_hyperparams, \n",
    "        initial_epoch=base_hyperparams['num_epochs'], \n",
    "        num_epochs=base_hyperparams['num_epochs'] + fine_hyperparams['num_epochs'],\n",
    "        callbacks=[tensorboard_callback]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def cross_validate(experiment_name, train_folds, valid_folds, model_params, base_hyperparams, fine_hyperparams):\n",
    "    models = []\n",
    "    train_accs, valid_accs, train_losses, valid_losses = [], [], [], []\n",
    "    for i, (train_ds, valid_ds) in enumerate(zip(train_folds, valid_folds)):\n",
    "        k = i + 1\n",
    "        experiment_name_fold = f'{experiment_name}: {k}-fold'\n",
    "        print(f'# -------------------- {experiment_name_fold} -------------------- #')\n",
    "        \n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=os.path.join('logs', experiment_name_fold)\n",
    "        )\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = create_model(model_params['image_shape'], model_params['num_classes'], base_hyperparams)\n",
    "        model, history = train_validate(\n",
    "            model=model, \n",
    "            train_ds=train_ds, \n",
    "            valid_ds=valid_ds, \n",
    "            hyperparams=base_hyperparams, \n",
    "            initial_epoch=0, \n",
    "            num_epochs=base_hyperparams['num_epochs'],\n",
    "            callbacks=[tensorboard_callback]\n",
    "        )\n",
    "\n",
    "        model = create_fine_tune_model(model, fine_hyperparams)\n",
    "        model, history = train_validate(\n",
    "            model=model, \n",
    "            train_ds=train_ds, \n",
    "            valid_ds=valid_ds, \n",
    "            hyperparams=fine_hyperparams, \n",
    "            initial_epoch=base_hyperparams['num_epochs'], \n",
    "            num_epochs=base_hyperparams['num_epochs'] + fine_hyperparams['num_epochs'],\n",
    "            callbacks=[tensorboard_callback]\n",
    "        )\n",
    "\n",
    "        train_acc = history.history['accuracy'][-1]\n",
    "        valid_acc = history.history['val_accuracy'][-1]\n",
    "        train_loss = history.history['loss'][-1]\n",
    "        valid_loss = history.history['val_loss'][-1]\n",
    "\n",
    "        print(f'{experiment_name} | Train Loss: {train_loss} | Train Accuracy: {train_acc} | Validation Loss: {valid_loss} | Validation Accuracy: {valid_acc}\\n')\n",
    "        \n",
    "        models.append(model)\n",
    "        train_accs.append(train_acc)\n",
    "        valid_accs.append(valid_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "    avg_train_acc = np.mean(train_accs)\n",
    "    avg_valid_acc = np.mean(valid_accs)\n",
    "    avg_train_loss = np.mean(train_loss)\n",
    "    avg_valid_loss = np.mean(valid_loss)\n",
    "\n",
    "    print(f'Avg Train Loss: {avg_train_loss} | Avg Train Accuracy: {avg_train_acc} | Avg Validation Loss: {avg_valid_loss} | Avg Validation Accuracy: {avg_valid_acc}\\n')\n",
    "    \n",
    "    return models\n",
    "\n",
    "\n",
    "def evaluate(model, test_ds):\n",
    "    predictions = model.predict(test_ds)\n",
    "    predicted_indices = tf.argmax(predictions, 1)\n",
    "    predicted_labels = predicted_indices.numpy()\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre pre-process images\n",
    "# python preprocess.py\n",
    "\n",
    "# Build dataset\n",
    "# python -m tensorflow_datasets.scripts.download_and_prepare --datasets=mri_dataset --module_import=datasets.mri_dataset --manual_dir=data/processed --data_dir=data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hist_norm(img):\n",
    "#     gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "#     norm_gray_img = cv.equalizeHist(gray_img)\n",
    "#     norm_img = cv.cvtColor(norm_gray_img, cv.COLOR_GRAY2RGB)\n",
    "#     return norm_img\n",
    "\n",
    "\n",
    "# def clahe(img, clipLimit=4, tileGridSize=(40, 40)):\n",
    "#     clahe = cv.createCLAHE(clipLimit, tileGridSize)\n",
    "#     gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "#     cl_img = clahe.apply(gray_img)\n",
    "#     cl_img = cv.cvtColor(cl_img, cv.COLOR_GRAY2RGB)\n",
    "#     return cl_img\n",
    "\n",
    "\n",
    "# data_folder = 'data'\n",
    "# raw_folder = 'raw'\n",
    "# processed_folder = 'processed'\n",
    "# dataset = 'mri_dataset'\n",
    "# train_folder = 'train'\n",
    "# test_folder = 'test'\n",
    "# train_label = 'train_label.csv'\n",
    "\n",
    "# img_path = os.path.join(data_folder, raw_folder, train_folder, '851.png')\n",
    "# img = cv.imread(img_path)\n",
    "# n_img = hist_norm(img)\n",
    "# clahe_img1 = clahe(img, clipLimit=8, tileGridSize=(32, 32))\n",
    "# clahe_img2 = clahe(img, clipLimit=8, tileGridSize=(8, 8))\n",
    "\n",
    "# # n_clahe_img = clahe(n_img, clipLimit=clip, tileGridSize=tile_size)\n",
    "# combined_imgs = np.hstack((img, clahe_img1, clahe_img2))\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# plt.imshow(combined_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  # Disable first GPU\n",
    "  tf.config.set_visible_devices(physical_devices[1:], 'GPU')\n",
    "  logical_devices = tf.config.list_logical_devices('GPU')\n",
    "  # Logical device was not created for first GPU\n",
    "  assert len(logical_devices) == len(physical_devices) - 1\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Mixed Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\nSome of your GPUs may run slowly with dtype policy mixed_float16 because they do not all have compute capability of at least 7.0. Your GPUs:\n  Tesla V100S-PCIE-32GB, compute capability 7.0\n  Tesla V100-PCIE-32GB, compute capability 7.0\n  Tesla P100-PCIE-16GB, compute capability 6.0 (x2)\nSee https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\nIf you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from datasets.mri_dataset import MriDataset\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "data_folder = 'data'\n",
    "raw_folder = 'raw'\n",
    "processed_folder = 'processed'\n",
    "dataset = 'mri_dataset'\n",
    "train_folder = 'train'\n",
    "test_folder = 'test'\n",
    "train_label = 'train_label.csv'\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "experiment_name = 'MobileNetV2'\n",
    "model_params = {\n",
    "    'image_shape': (512, 512, 3),\n",
    "    'num_classes': 3,\n",
    "}\n",
    "base_hyperparams = {\n",
    "    'train_batch_size': 64,\n",
    "    'valid_batch_size': 64,\n",
    "    'test_batch_size': 64,\n",
    "    'num_epochs': 1,\n",
    "    'learning_rate': 1e-4,\n",
    "    'dropout': 0.2\n",
    "}\n",
    "fine_hyperparams = {\n",
    "    'num_epochs': 1,\n",
    "    'learning_rate': 1e-5,\n",
    "    'fine_tune_at': 100,\n",
    "}\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "train_folds = tfds.load(\n",
    "    name='mri_dataset', \n",
    "    split=[f'train[:{k}%]+train[{k+10}%:]' for k in range(0, 100, 20)],\n",
    "    download=False, \n",
    "    shuffle_files=False, \n",
    "    as_supervised=True,\n",
    "    data_dir=data_folder\n",
    ")\n",
    "valid_folds = tfds.load(\n",
    "    name='mri_dataset', \n",
    "    split=[f'train[{k}%:{k+10}%]' for k in range(0, 100, 20)],\n",
    "    download=False, \n",
    "    shuffle_files=False, \n",
    "    as_supervised=True,\n",
    "    data_dir=data_folder\n",
    ")\n",
    "test_ds_raw, test_info_raw = tfds.load(\n",
    "    name='mri_dataset', \n",
    "    split='test', \n",
    "    download=False, \n",
    "    shuffle_files=False, \n",
    "    as_supervised=False, \n",
    "    with_info=True,\n",
    "    data_dir=data_folder\n",
    ")\n",
    "\n",
    "train_folds = [ preprocess(ds, model_params, batch_size=base_hyperparams['train_batch_size'], ds_type='train') for ds in train_folds ]\n",
    "valid_folds = [ preprocess(ds, model_params, batch_size=base_hyperparams['valid_batch_size'], ds_type='valid') for ds in valid_folds ]\n",
    "test_ds = preprocess(test_ds_raw, model_params, batch_size=base_hyperparams['test_batch_size'], ds_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of train batches: 17\nNumber of valid batches: 2\nNumber of test batches: 5\n"
     ]
    }
   ],
   "source": [
    "train_valid_df = pd.read_csv(os.path.join(data_folder, processed_folder, train_label))\n",
    "train_ds = train_folds[0]\n",
    "valid_ds = valid_folds[0]\n",
    "\n",
    "print(f'Number of train batches: {train_ds.cardinality()}')\n",
    "print(f'Number of valid batches: {valid_ds.cardinality()}')\n",
    "print(f'Number of test batches: {test_ds.cardinality()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "K5BeQyKThC_Y"
   },
   "outputs": [],
   "source": [
    "# # disable image resize and rescale in preprocess function ONLY for visualisation\n",
    "# # Train Data\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(9):\n",
    "#     for i in range(9):\n",
    "#       ax = plt.subplot(3, 3, i + 1)\n",
    "#       plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#       plt.title(labels[i].numpy())\n",
    "#       plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test Data\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i, ds in enumerate(test_ds_raw.take(9)):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(ds['image'].numpy().astype(\"uint8\"))\n",
    "#     plt.title('ID: {}'.format(ds['id'].numpy()))\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aQullOUHkm67"
   },
   "outputs": [],
   "source": [
    "# TODO: Fix visualisation\n",
    "# data_augmentation = create_augmentation_layer()\n",
    "\n",
    "# for image, _ in train_ds.take(1):\n",
    "#   plt.figure(figsize=(10, 10))\n",
    "#   first_image = image[0]\n",
    "#   for i in range(9):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "#     plt.imshow(augmented_image[0] / 255)\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validate"
   ]
  },
  {
   "source": [
    "### Feature Extraction + Fine Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 1.3564 - accuracy: 0.1719WARNING:tensorflow:From /home/zongsien/MedicalImageClassifier/env/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:From /home/zongsien/MedicalImageClassifier/env/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "17/17 [==============================] - 9s 540ms/step - loss: 1.2518 - accuracy: 0.2710 - val_loss: 1.0954 - val_accuracy: 0.4138\n",
      "Number of layers in the base model:  155\n",
      "Epoch 2/2\n",
      " 2/17 [==>...........................] - ETA: 4s - loss: 1.1334 - accuracy: 0.4297WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1332s vs `on_train_batch_end` time: 0.4601s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1332s vs `on_train_batch_end` time: 0.4601s). Check your callbacks.\n",
      "17/17 [==============================] - 5s 280ms/step - loss: 0.9306 - accuracy: 0.5754 - val_loss: 0.7640 - val_accuracy: 0.6983\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(SEED)\n",
    "\n",
    "model = feature_extract_and_fine_tune(experiment_name, train_ds, valid_ds, model_params, base_hyperparams, fine_hyperparams)"
   ]
  },
  {
   "source": [
    "### K-Fold Cross Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ain Loss: 0.9243298768997192 | Train Accuracy: 0.569656491279602 | Validation Loss: 0.7638368010520935 | Validation Accuracy: 0.6982758641242981\n",
      "\n",
      "# -------------------- MobileNetV2: 2-fold -------------------- #\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      " 2/17 [==>...........................] - ETA: 6s - loss: 1.1389 - accuracy: 0.4453WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1152s vs `on_train_batch_end` time: 0.7020s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1152s vs `on_train_batch_end` time: 0.7020s). Check your callbacks.\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.1088 - accuracy: 0.4494WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda5b6b1050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda5b6b1050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "17/17 [==============================] - 3s 203ms/step - loss: 1.1088 - accuracy: 0.4494 - val_loss: 1.1113 - val_accuracy: 0.4569\n",
      "Number of layers in the base model:  155\n",
      "Epoch 2/2\n",
      " 2/17 [==>...........................] - ETA: 11s - loss: 1.0438 - accuracy: 0.4531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1880s vs `on_train_batch_end` time: 1.2631s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1880s vs `on_train_batch_end` time: 1.2631s). Check your callbacks.\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8602 - accuracy: 0.6279WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda54643290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda54643290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 0.8602 - accuracy: 0.6279 - val_loss: 0.7770 - val_accuracy: 0.6638\n",
      "MobileNetV2 | Train Loss: 0.8602254986763 | Train Accuracy: 0.6278625726699829 | Validation Loss: 0.7769647836685181 | Validation Accuracy: 0.6637930870056152\n",
      "\n",
      "# -------------------- MobileNetV2: 3-fold -------------------- #\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      " 2/17 [==>...........................] - ETA: 7s - loss: 1.2559 - accuracy: 0.3281WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1101s vs `on_train_batch_end` time: 0.8809s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1101s vs `on_train_batch_end` time: 0.8809s). Check your callbacks.\n",
      "16/17 [===========================>..] - ETA: 0s - loss: 1.1964 - accuracy: 0.3301WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda4f690170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda4f690170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "17/17 [==============================] - 4s 215ms/step - loss: 1.1988 - accuracy: 0.3254 - val_loss: 1.1870 - val_accuracy: 0.3966\n",
      "Number of layers in the base model:  155\n",
      "Epoch 2/2\n",
      " 2/17 [==>...........................] - ETA: 9s - loss: 1.0838 - accuracy: 0.4766WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1422s vs `on_train_batch_end` time: 1.1795s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1422s vs `on_train_batch_end` time: 1.1795s). Check your callbacks.\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8947 - accuracy: 0.6279WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda4c869950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda4c869950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "17/17 [==============================] - 4s 264ms/step - loss: 0.8947 - accuracy: 0.6279 - val_loss: 0.7591 - val_accuracy: 0.7414\n",
      "MobileNetV2 | Train Loss: 0.894716739654541 | Train Accuracy: 0.6278625726699829 | Validation Loss: 0.759141743183136 | Validation Accuracy: 0.7413793206214905\n",
      "\n",
      "# -------------------- MobileNetV2: 4-fold -------------------- #\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      " 2/17 [==>...........................] - ETA: 10s - loss: 1.5800 - accuracy: 0.1953WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.5334s vs `on_train_batch_end` time: 0.8764s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.5334s vs `on_train_batch_end` time: 0.8764s). Check your callbacks.\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.3612 - accuracy: 0.2464WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda476ee560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda476ee560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "17/17 [==============================] - 11s 621ms/step - loss: 1.3612 - accuracy: 0.2464 - val_loss: 1.1620 - val_accuracy: 0.4444\n",
      "Number of layers in the base model:  155\n",
      "Epoch 2/2\n",
      " 2/17 [==>...........................] - ETA: 10s - loss: 1.2200 - accuracy: 0.3203WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3036s vs `on_train_batch_end` time: 1.0743s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3036s vs `on_train_batch_end` time: 1.0743s). Check your callbacks.\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9642 - accuracy: 0.5377WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda46c7ddd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda46c7ddd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "17/17 [==============================] - 5s 318ms/step - loss: 0.9642 - accuracy: 0.5377 - val_loss: 0.8304 - val_accuracy: 0.6410\n",
      "MobileNetV2 | Train Loss: 0.9641729593276978 | Train Accuracy: 0.5377268195152283 | Validation Loss: 0.8304318189620972 | Validation Accuracy: 0.6410256624221802\n",
      "\n",
      "# -------------------- MobileNetV2: 5-fold -------------------- #\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      " 2/17 [==>...........................] - ETA: 7s - loss: 1.1163 - accuracy: 0.4062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1846s vs `on_train_batch_end` time: 0.7696s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1846s vs `on_train_batch_end` time: 0.7696s). Check your callbacks.\n",
      "16/17 [===========================>..] - ETA: 0s - loss: 1.1231 - accuracy: 0.3799WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda3d6958c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda3d6958c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "17/17 [==============================] - 4s 214ms/step - loss: 1.1230 - accuracy: 0.3792 - val_loss: 1.0629 - val_accuracy: 0.4615\n",
      "Number of layers in the base model:  155\n",
      "Epoch 2/2\n",
      " 2/17 [==>...........................] - ETA: 8s - loss: 1.0362 - accuracy: 0.4766WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1195s vs `on_train_batch_end` time: 1.0548s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1195s vs `on_train_batch_end` time: 1.0548s). Check your callbacks.\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8689 - accuracy: 0.6084WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda3ac81950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fda3ac81950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "17/17 [==============================] - 4s 252ms/step - loss: 0.8689 - accuracy: 0.6084 - val_loss: 0.7209 - val_accuracy: 0.7265\n",
      "MobileNetV2 | Train Loss: 0.86894291639328 | Train Accuracy: 0.6084049940109253 | Validation Loss: 0.7208523750305176 | Validation Accuracy: 0.7264957427978516\n",
      "\n",
      "Avg Train Loss: 0.86894291639328 | Avg Train Accuracy: 0.5943026900291443 | Avg Validation Loss: 0.7208523750305176 | Avg Validation Accuracy: 0.6941939353942871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(SEED)\n",
    "\n",
    "models = cross_validate(experiment_name, train_folds, valid_folds, model_params, base_hyperparams, fine_hyperparams)\n",
    "#     print('Saving model\\n')\n",
    "#     filename = os.path.join('models', experiment_name, '.h5')\n",
    "#     model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(SEED)\n",
    "# hyperparams = {\n",
    "#     'initial_epochs': 150,\n",
    "#     'learning_rate': 1e-4,\n",
    "#     'label_smoothing': 0.1,\n",
    "# }\n",
    "# experiment_name = f'Ensemble02'\n",
    "\n",
    "\n",
    "# ensemble_model = create_ensemble_model()\n",
    "# train_ds = ensemble_input(train_folds[3], ds_type='train')\n",
    "# valid_ds = ensemble_input(valid_folds[3], ds_type='valid')\n",
    "# ensemble_model = train_validate(ensemble_model, train_ds, valid_ds, hyperparams, experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ds = ensemble_input(test_ds, ds_type='train')\n",
    "# predictions = ensemble_model.predict(test_ds)\n",
    "# predicted_indices = tf.argmax(predictions, 1)\n",
    "# predicted_labels = predicted_indices.numpy()\n",
    "# img_ids = tfds.as_dataframe(test_ds_raw, test_info_raw)\n",
    "# save_results('Ensemble02_submission.csv', img_ids, predicted_labels)\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6cWgjgfrsn5"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "RUNoQNgtfNgt"
   },
   "outputs": [],
   "source": [
    "# TODO: analyse predicted results\n",
    "# image_batch, label_batch = valid_ds.as_numpy_iterator().next()\n",
    "# predictions = model.predict_on_batch(image_batch)\n",
    "# predicted_indices = tf.argmax(predictions, 1)\n",
    "# predicted_labels = predicted_indices.numpy()\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(9):\n",
    "#   ax = plt.subplot(3, 3, i + 1)\n",
    "#   plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "#   plt.title(f'pred: {predicted_labels[i]} true: {label_batch[i]}')\n",
    "#   plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 2, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 2, 0, 1, 2, 1, 1, 2, 2,\n",
       "       0, 1, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 0, 0, 1, 1, 2, 0, 0, 1, 1,\n",
       "       2, 1, 1, 2, 2, 0, 1, 0, 2, 0, 2, 1, 0, 1, 2, 1, 0, 1, 0, 0, 2, 1,\n",
       "       1, 1, 2, 0, 0, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 0, 2, 1, 1, 1, 2, 1,\n",
       "       1, 1, 2, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2,\n",
       "       1, 0, 2, 0, 1, 2, 0, 1, 2, 1, 0, 1, 2, 1, 1, 0, 1, 2, 0, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 2, 1, 1, 1, 2,\n",
       "       2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 1, 2, 1,\n",
       "       1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 0, 1,\n",
       "       0, 1, 0, 1, 1, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2,\n",
       "       1, 2, 1, 1, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# predict test labels\n",
    "predicted_labels = evaluate(model, test_ds)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_save_path = experiment_name + '_' + 'submission.csv'\n",
    "img_ids = tfds.as_dataframe(test_ds_raw, test_info_raw)\n",
    "save_results(img_ids, predicted_labels, result_save_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transfer_learning.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}